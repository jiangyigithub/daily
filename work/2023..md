# April
## 4/13
## 4/17
- PI planning
## 4/18

## 4/23
1. debug ros python node `launch-prefix="xterm -e python -m pdb"`  
    for more: http://wiki.ros.org/roslaunch/Tutorials/Roslaunch%20Nodes%20in%20Valgrind%20or%20GDB
    python `PDB`: https://realpython.com/python-debugging-pdb/#getting-started-printing-a-variables-value
    ```bash
    # Set a breakpoint at line 10 of the current file
    break 10

    # Set a breakpoint at line 20 of the file "my_script.py"
    break my_script.py:20

    # Set a breakpoint at the start of the function "my_function"
    break my_script.my_function

    # Set a conditional breakpoint at line 30 of the current file
    break 30, some_variable == True
    ```

2. ros log `logwarn_throttle`  
    In ROS, logwarn_throttle is a method provided by the rospy Python library that allows you to log warning messages at a throttled rate.

    The logwarn_throttle method is similar to the rospy.logwarn method, but it limits the rate at which warning messages are printed to the console. This can be useful in situations where you have a large number of warnings that could overwhelm the console output, or when you want to avoid repeatedly printing the same warning message.

    Here's an example of how to use logwarn_throttle in a rospy node:
    ```python
    import rospy

    rospy.init_node('my_node')

    # Set the warning throttle rate to 10 seconds
    rospy.logwarn_throttle(10, "My warning message")

    # This warning message will only be printed every 10 seconds
    rospy.logwarn_throttle(10, "My warning message")

    # This warning message will be printed immediately
    rospy.logwarn("Another warning message")
    ```

    In this example, we first initialize a rospy node with the name "my_node".

    We then use the rospy.logwarn_throttle method to log a warning message with a throttle rate of 10 seconds. This means that the warning message will only be printed once every 10 seconds, even if the logwarn_throttle method is called multiple times.

    We then call logwarn_throttle again with the same warning message. Since the throttle rate is set to 10 seconds, this warning message will not be printed immediately, but will be queued and printed after the 10 second throttle period has elapsed.

    Finally, we use the rospy.logwarn method to log another warning message. This message will be printed immediately, regardless of the throttle rate set by logwarn_throttle.

    Note that logwarn_throttle can be used with any warning message, not just the string "My warning message" used in this example. You can also adjust the throttle rate to a different value by changing the first argument to logwarn_throttle.

3. `get_num_connections` for ROS python  
    In this code snippet, the get_num_connections() method is used to check if there are any subscribers to the topic associated with self.publisher.

    If get_num_connections() returns a value of 0, it means that there are no subscribers to the topic at the moment. In this case, the code returns from the function and does not publish the message.

    This can be useful in situations where you want to avoid publishing messages if there are no subscribers to the topic. By checking the number of connections before publishing the message, you can avoid unnecessary network traffic and processing.

    Here's an example of how you might use this code snippet in a rospy node:

    ```python

    import rospy
    from std_msgs.msg import String

    class MyNode:
        def __init__(self):
            self.publisher = rospy.Publisher('my_topic', String, queue_size=10)

        def publish_message(self, message):
            if self.publisher.get_num_connections() == 0:
                return
            self.publisher.publish(message)

    rospy.init_node('my_node')
    node = MyNode()

    message = String()
    message.data = 'Hello, world!'

    node.publish_message(message)
    ```

    In this example, we define a MyNode class with a publish_message() method that publishes a message to the my_topic topic if there are subscribers to the topic.

    We then initialize a rospy node, create a MyNode object, and call the publish_message() method with a String message.

    If there are no subscribers to the my_topic topic, the publish_message() method will return without publishing the message. If there are subscribers, the message will be published as usual.

## 4/24
1. RVIZ visulization

    RViz Plugin Development: This topic covers the development of custom RViz plugins for displaying custom visualizations in RViz. It includes topics such as creating custom `displays`, `panels`, and tools, as well as integrating custom ROS messages and services.

2. how to define coordinate frames in ROS

    ROS TF Transforms: This topic covers the use of the ROS TF (Transform) package for managing coordinate frames in ROS. It includes topics such as defining coordinate frames using URDF files or using a TF broadcaster node in robot software, as well as transforming coordinates between frames.
    - URDF (Unified Robot Description Format) file: URDF is an XML format used to describe a robot model. It includes information about the robot's links, joints, sensors, and other features. URDF files can be used to define coordinate frames for various parts of the robot.

    - TF broadcaster node: A TF broadcaster node is a ROS node that publishes transformations between coordinate frames. This node can be part of your robot software, and it can broadcast transformations based on sensor data or other inputs.[odometry demo](http://wiki.ros.org/navigation/Tutorials/RobotSetup/Odom)

3. vector usage  
    get element by the operation[], the system crash

## 4/26
1. Rviz:what the difference of panel and display in ros rviz  
    In ROS RViz, both "panels" and "displays" are used to visualize data, but they serve different purposes.

    A "panel" in RViz is a graphical user interface (GUI) component that provides additional functionality beyond what is provided by the main RViz display. Panels are typically used to modify the behavior or appearance of a display or to provide additional information about the data being visualized. For example, a panel might allow you to change the color of a marker, adjust the size of a point cloud, or enter a destination for a robot.

    A "display" in RViz, on the other hand, is the main component responsible for visualizing data. Displays are used to show data such as point clouds, laser scans, images, and other types of sensor data. Each display is associated with a particular topic in ROS, and updates its visualization whenever new data is received on that topic. Displays can be configured to show data in different ways, such as using different colors, sizes, or styles.

    In summary, panels are used to provide additional functionality or information to the user, while displays are used to actually visualize the data. Panels and displays can work together to create more powerful and customizable visualizations in RViz.

2. foxglove
    - To visualize a topic, the messages on that topic must conform to one of the known message schemas listed below.
    [message schemas list](https://foxglove.dev/docs/studio/panels/3d)
    - remapping topic , https://foxglove.dev/blog/using-message-converters-to-display-3d-markers-in-foxglove-studio
    - custom panel, 
    - User Scripts, https://foxglove.dev/docs/studio/panels/user-scripts

3. ROS TF

    [Robotics-Tutorial]https://articulatedrobotics.xyz/page2/
    http://wiki.ros.org/navigation/Tutorials/RobotSetup/TF

## 4/27
1. [ROS lecture](https://rsl.ethz.ch/education-students/lectures/ros.html)
2. how to get the value of shared pointer *share_pointer
3. common ROS message:
  pcl::PointCloud<pcl::PointXYZI> 
  sensor_msgs::PointCloud2>
4. ROS pub-sub most important concept
    - declare pub
    - define advertise
    - publish
    - constructor and callback
    - topic type and topic name

## 4/28
1. TF to static publish
rosrun tf2_ros static_transform_publisher 0.2 0 0.5 0 0 0 /baselink /laser 
https://zhuanlan.zhihu.com/p/358816230

2. foxglove message
ros_foxglove_msgs

# May
## 5/8
1. TF
  how to check TF status: http://wiki.ros.org/tf/Debugging%20tools
  traditional https://www.ros.org/reps/rep-0105.html

  https://inside-docupedia.bosch.com/confluence/display/MFAD/RRS+Coordinate+System+Study
  https://inside-docupedia.bosch.com/confluence/display/HAD/Sensor

2. summary of material
  [Robotics-Tutorial]https://articulatedrobotics.xyz/page2/
  [ROS lecture](https://rsl.ethz.ch/education-students/lectures/ros.html)
  [autonomous-racing-course]https://linklab-uva.github.io/autonomousracing/page3.html#content10-u

3. ssh connect in vscode
 in bottom left of vscode

4. cmake build 
  check the temp cmake generate file
  build/geographic_transform/CMakeCache.txt

  //The directory containing a CMake configuration file for Boost.
  Boost_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Boost-1.71.0

  //Path to a file.
  Boost_INCLUDE_DIR:PATH=/usr/include

  Boost_PYTHON_LIBRARY_RELEASE:STRING=/usr/lib/x86_64-linux-gnu/libboost_python38.so.1.71.0


## 5/10
1. visualization objects in foxglove
  - visualization_msgs/Marker.msg  --> for raw ROS message
  - foxglove_msgs/CubePrimitive.msg --> for foxglove message
    ```python
    # Position of the center of the cube and orientation of the cube
    geometry_msgs/Pose pose

    # Size of the cube along each axis
    geometry_msgs/Vector3 size

    # Color of the cube
    foxglove_msgs/Color color
    ```
    ```python
    geometry_msgs/Pose pose                 # Pose of the object
    geometry_msgs/Vector3 scale             # Scale of the object 1,1,1 means default (usually 1 meter square)
    std_msgs/ColorRGBA color             # Color [0.0-1.0]
    ```

2. CAN driver
    The CAN (Controller Area Network) protocol driver is a software component that enables communication between a computer or microcontroller and a CAN bus. The CAN protocol is commonly used in automotive and industrial applications for reliable and robust data communication.

    A CAN protocol driver typically provides an abstraction layer between the hardware and the application layer. It handles the low-level details of sending and receiving CAN messages, implementing the protocol's rules, and managing the hardware interfaces. The driver allows the application to interact with the CAN bus by providing a set of APIs (Application Programming Interfaces) or functions.

    Here are some key aspects of a CAN protocol driver:

        Initialization: The driver initializes the CAN controller and sets up the necessary hardware configurations, such as bitrate, acceptance filters, and error handling settings.

        Transmitting Messages: The driver provides functions to send CAN messages onto the bus. It takes care of packaging the data into the appropriate CAN message format and handling acknowledgments.

        Receiving Messages: The driver continuously listens to the CAN bus and receives incoming messages. It handles message filtering based on configured acceptance filters and delivers received messages to the application.

        Error Handling: The driver monitors and reports various error conditions that may occur on the CAN bus, such as bus-off, error frames, or transmission failures. It can also implement error recovery mechanisms.

        Synchronization and Timing: The driver ensures proper synchronization with the CAN bus and manages the timing requirements of the protocol, such as bit timing, synchronization segments, and arbitration rules.

        Configuration and Control: The driver allows the application to configure various parameters, such as bitrate, acceptance filters, and error handling settings, and provides control over the CAN controller, such as starting or stopping communication.

    CAN protocol drivers are available for different platforms and programming languages. They can be provided by the hardware manufacturer or developed by third-party software vendors. These drivers abstract the complexity of the underlying CAN hardware, making it easier for application developers to work with CAN networks and exchange data reliably.

    By utilizing a CAN protocol driver, developers can focus on implementing the higher-level functionality of their applications while leveraging the driver's capabilities for efficient and standardized communication over the CAN bus.

3. linux virtual CAN
    https://inside-docupedia.bosch.com/confluence/display/CRSHUT/Linux+CAN+Tools

    ```bash
    # Install CAN Tools
    $ sudo pip install cantools
    $ sudo apt install can-utils

    #Set up virtual CAN
    $ sudo modprobe vcan
    $ sudo ip link add can0 type vcan
    $ sudo ip link set can0 up

    #Show CAN Statistics
    $ ip -s -d link show can0

    #Send data to CAN
    $ cansend can0 200#DEADBEEFDEADBEEF
    $ while true; do cansend can0 200#DEADBEEFDEADBEEF; done

    #Dump CAN data
    ## Raw data:
    $ candump can0

    ## Filter by CAN Id:
    $ candump -c -ta can0,200:FFF

    #Play and Record CAN to Vector Format (*.BLF)
    ##Play:
    $ python -m can.player -i socketcan -c can0 test.blf

    ##Record:
    $ python -m can.logger -i socketcan -c can0 -f test.blf
    ```

4. linux file permission
chmod 777

## 5/11
1. URDF(fixed_joint)  
    In URDF, a fixed joint is used to represent a rigid connection between two links. The fixed joint does not allow any relative movement or rotation between the connected links. Here's an example of how to define a fixed joint in a URDF file:

    ```xml
    <?xml version="1.0" ?>
    <robot name="my_robot">

      <link name="link1">
        <!-- Define visual and collision properties for link1 -->
      </link>

      <link name="link2">
        <!-- Define visual and collision properties for link2 -->
      </link>

      <!-- Fixed joint -->
      <joint name="fixed_joint" type="fixed">
        <parent link="link1" />
        <child link="link2" />
        <origin xyz="1 0 0" rpy="0 0 0" />
      </joint>

    </robot>
    ```

    In this example, we have two links (`link1` and `link2`) connected by a fixed joint called `fixed_joint`. Here's a breakdown of the elements:

    - `<joint>`: This tag represents the joint element in the URDF.
      - `name`: Specifies the name of the joint (`fixed_joint` in this example).
      - `type`: Specifies the type of joint, which is `fixed` for a fixed joint.
    - `<parent>`: Specifies the parent link that the joint is connected to. In this case, the parent link is `link1`.
    - `<child>`: Specifies the child link that the joint is connected to. Here, the child link is `link2`.
    - `<origin>`: Defines the position and orientation of the joint relative to the parent link. The `xyz` attribute represents the translation, and the `rpy` attribute represents the roll, pitch, and yaw angles of the joint.

    By defining a fixed joint between `link1` and `link2`, you establish a rigid connection between them, allowing no relative motion or rotation.

    Remember to add visual and collision properties for each link to complete the URDF description.

    You can use this example as a starting point and extend it with additional links, joints, and other elements as needed for your specific robot model.

2. URDF with Xacro  
    Sure! Here's a tutorial on creating a URDF with Xacro and using it to define transformations using the TF (Transform) library in ROS:
    Step 1: Set up a ROS Package
    Create a new ROS package or use an existing one where you want to store your URDF files. Open a terminal and navigate to your ROS workspace.

    ```bash
    cd ~/catkin_ws/src
    catkin_create_pkg my_robot_description
    ```

    Step 2: Create the Xacro File
    Inside the `my_robot_description` package, create a `urdf` folder and a new Xacro file, e.g., `my_robot.xacro`. You can use any text editor to create the file.

    ```bash
    cd my_robot_description
    mkdir urdf
    touch urdf/my_robot.xacro
    ```

    Step 3: Edit the Xacro File
    Open `my_robot.xacro` in a text editor and define your robot's structure using Xacro macros and elements. Below is an example of a two-link robot with transformations:

    ```xml
    <?xml version="1.0" ?>
    <robot xmlns:xacro="http://ros.org/wiki/xacro" name="my_robot">

      <xacro:macro name="link" params="link_name">
        <link name="${link_name}">
          <!-- Define visual and collision properties for the link -->
        </link>
      </xacro:macro>

      <xacro:macro name="joint" params="joint_name parent_link child_link">
        <joint name="${joint_name}" type="fixed">
          <parent link="${parent_link}" />
          <child link="${child_link}" />
          <origin xyz="0 0 0" rpy="0 0 0" />
        </joint>
      </xacro:macro>

      <!-- Define the links and joints -->
      <xacro:link link_name="base_link" />
      <xacro:link link_name="link1" />
      <xacro:link link_name="link2" />

      <xacro:joint joint_name="joint1" parent_link="base_link" child_link="link1" />
      <xacro:joint joint_name="joint2" parent_link="link1" child_link="link2" />

    </robot>
    ```

    In this example, we use Xacro macros (`<xacro:macro>`) to define the link and joint elements. The macros allow us to reuse code and simplify the structure of the URDF. The `link` macro defines a link element, and the `joint` macro defines a fixed joint element.

    Step 4: Generate the URDF File
    To generate the URDF file from the Xacro file, you need to run the `xacro` command-line tool. In your package's CMakeLists.txt file, add the following lines to generate the URDF file during the build process:

    ```cmake
    # CMakeLists.txt

    # Find xacro package
    find_package(xacro REQUIRED)

    # Generate URDF file from Xacro
    xacro_add_xacro_file(urdf/my_robot.urdf.xacro urdf/my_robot.urdf)

    # Include URDF in the install target
    install(FILES ${CMAKE_CURRENT_BINARY_DIR}/urdf/my_robot.urdf DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}/urdf)
    ```

    Step 5: Build and Launch the URDF
    Build the package using `catkin_make` and launch the robot model in RViz to visualize it.

    ```bash
    cd ~/catkin_ws
    catkin_make
    source devel/setup.bash
    roslaunch my_robot_description display.launch model:=urdf/my_robot.urdf
    ```

    You should now see the robot model displayed in RViz

3. for our project
  - xacro
  - URDF
  - xacro_add_xacro_file # Generate URDF file from Xacro
  - robot_state_publisher # Publish TF transforms
```cmake
  set(expanded_file "${CMAKE_CURRENT_BINARY_DIR}/frames/${basename}.urdf")
  message(STATUS "    produce expanded file :" ,${expanded_file})

  xacro_add_xacro_file(${it} ${expanded_file} INORDER)
```

the output file:
build/vw01_golf_3654/frames/urdf.urdf

```xml ros launch file
  <param name="robot_description" command="$(find xacro)/xacro --inorder '$(find icv_golf)/frames/urdf.xacro'"/>
  
  <!-- Publish TF transforms from vehicle origin to sensors -->
  <node pkg="robot_state_publisher" type="state_publisher" name="robot_state_publisher">
    <!-- Do not use static tf transforms. They will not be published when playing a bag file not from the beginning -->
    <param name="use_tf_static" value="false" />
  </node>
```

## 5/12
1. how to find .lib in linux
Verify the library path: Ensure that the library path is correct and accessible to CMake. Double-check the output of `ldconfig -p | grep eci` to confirm the exact library name and path.

2. can driver -ixxat
https://www.ixxat.com/products/pc-interfaces-overview/details/can-ib600-pcie?ordercode=1.01.0233.12010

3. TF tutorial
https://foxglove.dev/blog/understanding-ros-transforms
https://rsl.ethz.ch/education-students/lectures/ros.html
{
TF Transformation System
rqt User Interface
Robot models (URDF)
Simulation descriptions (SDF)
}

4. robot business
https://www.roboticsbusinessreview.com/wp-content/uploads/2022/04/rbr50-2022-final.pdf

## 5/15
1. ROS version --> rosversion -d
ROS package location --> rospack find robot_state_publisher

2. publish TF
rosparam set /robot_description -t /home/jan5szh/workspaces/icv_ipc/build/icv_golf/frames/urdf.urdf
rosrun robot_state_publisher robot_state_publisher

## 5/16
1. CAN /CANFD
CANFD --> DLC 1111(15) max=64
CAN --> DLC max=8
https://en.wikipedia.org/wiki/CAN_bus
[!CAN-bus-frame-with-stuff-bit-and-correct-CRC.png](source/CAN-bus-frame-with-stuff-bit-and-correct-CRC.png)

## 5/17
1. TOP95-lukas docker ROS
https://sourcecode.socialcoding.bosch.com/projects/IAD/repos/top95_lukas_container/browse

2. sudo su

## 5/18
1. UDP 
2. google - protocol buffer (src/ux/hololens)
3. radar RCS 
4. AI transformer attention

## 5/24
1. linux bashrc
alias srm=~/tools/simple_repository_manager/srm.py

## 5/25
ROS2 USB Camera:https://github.com/ros-drivers/usb_cam

ROS1 USB Camera
https://charon-cheung.github.io/2018/11/14/ROS/ROS%E6%9C%BA%E5%99%A8%E4%BA%BA/ROS%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEUSB%E6%91%84%E5%83%8F%E5%A4%B4/#%E8%BF%90%E8%A1%8C%E5%92%8C%E9%85%8D%E7%BD%AE
https://blog.csdn.net/w1820020635/article/details/127355344

## 5/26
### CAN driver
1. install
[CAN driver](https://www.ixxat.com/zh/products/pc-interfaces-overview/details/can-ib600-pcie?ordercode=1.01.0233.12010)

2. generate .ko file
A .ko file in Linux refers to a kernel module file. Kernel modules are pieces of code that can be loaded into the kernel at runtime to extend its functionality or add support for specific hardware or features. These modules are typically used in the Linux kernel to support various device drivers.
>> 下载ixxat的驱动(https://www.ixxat.com/zh/products/pc-interfaces-overview/details/can-ib600-pcie?ordercode=1.01.0233.12010)
>> 进到/home/hny2wx/eci-linux/EciLinux_amd64/src/KernelModule目录下，执行`sudo make install`

3. install by kmodsign sha256
[kernel]sudo kmodsign sha256 /var/lib/shim-signed/mok/MOK.priv /var/lib/shim-signed/mok/MOK.der "/home/jan5szh/Downloads/EciLinux_amd64/src/KernelModule/ecikm.ko"

4. check system status and driver status

mokutil --sb-state
ldconfig -p | grep eci

5. close secure boot
ilab or itrepair is the BIOS passwd

### docker
1. 拉镜像
docker pull boschicv/icv-noetic:v5.0

2. 制作容器
sudo docker run -it --privileged --name icv-lukas -v /home/jan5szh/workspace:/workspace boschicv/icv-noetic:v5.0

3. How to Start Docker Container
docker start

4. 进到容器内部
sudo docker exec -it xxx /bin/bash

## 5/29
### web server
1. epoll
`网络 I/O 模型`
网络I/O模型是用来描述在网络编程中，如何进行输入和输出操作的模型。以下是常见的网络I/O模型：

    阻塞I/O（Blocking I/O）：在阻塞I/O模型中，当应用程序进行网络I/O操作时，会阻塞（即停止执行）直到操作完成。当调用一个阻塞I/O函数（如读或写）时，程序会一直等待直到数据准备好或写入完成。阻塞I/O适用于处理连接数较少且每个连接处理时间较长的情况，但它可能导致程序在等待I/O完成时无法执行其他任务。

    非阻塞I/O（Non-blocking I/O）：非阻塞I/O模型中，应用程序发起一个I/O操作后会立即返回，而不会阻塞等待操作完成。通过轮询或者事件通知机制，应用程序可以检查I/O操作的状态，如果操作已经完成，就可以读取或写入数据。非阻塞I/O适用于处理连接数较多但每个连接处理时间较短的情况，它可以充分利用CPU资源，但会增加代码复杂性。

    I/O复用（I/O Multiplexing）：I/O复用模型通过使用单个线程来监视多个I/O事件的状态，从而实现高并发处理。它使用select、poll、epoll等系统调用来监视多个文件描述符（包括网络套接字），并在有I/O事件发生时通知应用程序。通过这种方式，应用程序可以同时处理多个连接而不会阻塞。I/O复用适用于处理连接数较多但每个连接处理时间较短的情况，它减少了对线程或进程的创建和管理，提高了系统的并发性能。

    信号驱动I/O（Signal-driven I/O）：信号驱动I/O模型使用信号机制来通知应用程序I/O事件的发生。应用程序首先使用sigaction函数来指定一个信号处理函数，然后调用非阻塞I/O函数启动一个I/O操作。当I/O操作完成时，操作系统会发送一个信号给应用程序，应用程序在信号处理函数中进行后续的处理。信号驱动I/O适用于处理连接数较多但每个连接处理时间较短的情况，它避免了轮询的开销，但对信号的处理需要谨慎。

    异步I/O（Asynchronous I/O）：异步I/O模型中，应用程序发起一个I/O操作后可以继续执行其他任务，而不需要等待操作完成。当I/O操作完成时，操作系统会通知应用程序，并将数据传输到应用程序指定的缓冲区。异步I/O适用于处理连接数较多且每个连接处理时间较长的情况，它可以充分利用系统资源，但实现和使用比较复杂。

不同的网络I/O模型适用于不同的应用场景，选择适合的模型可以提高网络应用的性能和可伸缩性。具体选择哪种模型要根据应用程序的特点、系统资源以及性能需求来进行评估和决策.

`不同的网络I/O模型适用于不同的应用场景`
不同的网络I/O模型适用于不同的应用场景，根据应用程序的需求和特点选择适合的模型可以提高性能和可伸缩性。下面是一些常见的应用场景和适合的网络I/O模型示例：

    高并发连接处理：当应用程序需要处理大量并发连接时，如Web服务器或聊天应用程序，可以考虑使用I/O复用模型（如epoll）。它可以通过单个线程高效地管理和处理多个连接，提供高并发性能。

    长连接的低延迟通信：如果应用程序需要保持长时间的持久连接，并且对低延迟通信要求较高，可以考虑使用非阻塞I/O模型。它允许应用程序在等待I/O完成的同时处理其他任务，减少了延迟。

    大数据传输：当应用程序需要传输大量数据，如文件传输或流媒体应用程序，可以考虑使用异步I/O模型。它允许应用程序发起I/O操作后继续执行其他任务，同时在操作完成后通知应用程序处理数据。

    实时数据处理：对于实时数据处理应用程序，如实时监控系统或金融交易系统，可以考虑使用信号驱动I/O模型。它通过信号机制及时通知应用程序有关I/O事件的发生，以便及时处理。

    简单应用程序：对于简单的应用程序，连接数较少且每个连接处理时间较长，可以选择阻塞I/O模型。它简单易用，但可能会阻塞整个应用程序的执行。

需要根据具体的应用需求、系统资源和性能目标综合考虑选择适合的网络I/O模型。同时，不同的操作系统和编程语言可能提供不同的网络I/O模型和API，可以根据实际情况选择合适的工具和框架。

2. thread pool
网络I/O模型和线程池是两个不同的概念，但它们可以结合使用来提高网络应用程序的性能和并发处理能力。

网络I/O模型定义了应用程序如何进行网络通信和处理I/O操作的方式，如阻塞I/O、非阻塞I/O、I/O复用、信号驱动I/O和异步I/O等。这些模型主要关注如何管理和处理网络连接以及对I/O事件的等待和处理。

线程池是一种管理和复用线程的机制，它维护一个线程池，其中包含多个预先创建的线程，用于执行应用程序的任务。线程池可以有效地管理线程的生命周期，避免频繁创建和销毁线程的开销，同时控制并发线程数量，避免过多的线程导致系统资源耗尽。

在网络应用程序中，可以结合网络I/O模型和线程池来提高并发处理能力。一种常见的做法是使用I/O复用模型（如epoll）来管理和处理多个连接，当有I/O事件发生时，将任务交给线程池中的线程进行处理。这样可以充分利用系统资源，同时实现高并发和高效的网络通信。

具体实现时，可以使用一个线程专门负责监听和接受新连接，将已建立的连接交给线程池中的线程进行处理。线程池中的线程可以使用非阻塞I/O模型来处理连接的读写操作，同时可以处理其他任务，提高系统的并发性能。

综上所述，网络I/O模型和线程池是两个不同的概念，但可以结合使用来提高网络应用程序的性能和并发处理能力。合理选择和配置适合的网络I/O模型和线程池大小，可以根据应用程序的需求和系统资源来进行优化。

3. HTTP
TCP/IP + socket + port
request + response

https://xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#%E6%80%BB%E7%BB%93
https://zhuanlan.zhihu.com/p/503390413
epoll 原理是如何实现的？ - 你丫才码农的回答 - 知乎
https://www.zhihu.com/question/486578358/answer/2534288200

## 5/30
## 5/31
1. rm .so lib
ldconfig
ldconfig -p|grep eci

cd /etc
rm ./ld.so.cache

2. how to handle the kernel driver lib build issue
```cmake
if(NOT EXISTS "/usr/lib/libeci111DriverLinux.so.1.11.3019.6")
  message(WARNING "Can kernel module missing. This package will now provide only a simulated can interface, which is only usable / valid on a development PC!")
  message(" #################################################")
  message(" #                                               #")
  message(" # For access to the actual can hardware this    #")
  message(" # package needs to be build against the correct #")
  message(" # can kernel module / ECI library!              #")
  message(" # Execute the INSTALL.sh script in can package! #")
  message(" #                                               #")
  message(" #################################################")

  # set up some defines to allow excluding kernel module dependencies
  add_definitions("-DDEV_PC") # define for cpp code
  
  # compile library without kernel module
  add_library(${PROJECT_NAME}
    src/can_ros_interface.cpp
    src/can_interface_factory.cpp
    src/cancore.cpp
  )
  target_link_libraries(${PROJECT_NAME} ${catkin_LIBRARIES})

else()

  # compile library with correct kernel module dependencies
  add_library(${PROJECT_NAME}
    src/canIxxat10A.cpp
    src/canIxxat111.cpp
    src/can_ros_interface.cpp
    src/can_interface_factory.cpp
    src/cancore.cpp
  )
  target_link_libraries(${PROJECT_NAME} eci10ADriverLinux eci111DriverLinux usb-1.0 ${catkin_LIBRARIES})

endif()
```
3. docker
https://sourcecode.socialcoding.bosch.com/projects/PERCEPTION_KIT/repos/deep_object_detection_container/browse/Dockerfile
https://sourcecode.socialcoding.bosch.com/projects/IAD/repos/top95_lukas_container/browse

# June
## 6/06
###  C++
1. shared_ptr
https://medium.com/analytics-vidhya/c-shared-ptr-and-how-to-write-your-own-d0d385c118ad
https://zhuanlan.zhihu.com/p/548864356

shared_ptr-like behavior with reference counting, the refCount variable is indeed a pointer to an integer, rather than an integer itself. This is because the refCount needs to be shared among multiple my_shared_ptr objects and maintain the same value for proper reference counting.

By using a pointer to an integer, all my_shared_ptr objects that share ownership of a particular resource can access and manipulate the same reference count value. Each my_shared_ptr object can increment or decrement the reference count as needed when it is created, copied, assigned, or destroyed.

If refCount were an integer variable instead of a pointer, each my_shared_ptr object would have its own separate copy of the reference count, and changes made by one object would not affect the others. This would result in incorrect reference counting and could lead to memory leaks or premature deallocation of resources.

Therefore, using a pointer to an integer allows multiple my_shared_ptr objects to share and synchronize the reference count, ensuring the correct management of the shared resource.


2. `constexpr` VS  `#define`
In C++, both constexpr double M_PI = 3.14 and #define M_PI 3.14 can be used to define the constant value of pi (π) as 3.14. However, there are some differences between the two approaches.

Scope: The constexpr statement is scoped like any other variable declaration. It respects the normal scoping rules of C++, and the constant is only accessible within its defined scope. On the other hand, the #define macro has a global scope. It performs a simple text substitution, replacing every occurrence of M_PI with 3.14 throughout the code.

Type Safety: When using constexpr, the compiler can perform type checking. In this case, M_PI is explicitly declared as a double type. If you accidentally assign it to a different type, the compiler will generate an error. With #define, there is no type checking because it performs textual substitution. Any occurrences of M_PI are replaced with 3.14, regardless of their type.

Debugging: When using constexpr, the constant value is known to the compiler, which can provide better debugging information. If you encounter an error or breakpoint while debugging, you will see the constant M_PI with its assigned value. With #define, since it is a simple text substitution, the constant M_PI is not visible during debugging. Instead, you will see 3.14 directly.

Expressiveness: constexpr allows you to declare constants using C++ syntax and take advantage of type safety and scoping rules. You can define more complex expressions or even use functions to compute the constant value. With #define, you are limited to simple textual substitutions, and the value cannot be modified or computed within the C++ language itself.

Overall, constexpr provides more advantages in terms of type safety, scoping, and expressiveness, making it a preferable choice for defining constants in modern C++ code. However, there may still be situations where #define macros are necessary, especially for compatibility reasons with legacy code or when using preprocessor-specific features.


### sensor
1. radar feature
if elevation quality =0, elevation angle is invalid, radar loc most feature spp in DACORE CMP
毫米波雷达具有许多功能和特点，包括以下一些关键特征：
目标的雷达截面积（Radar Cross Section, RCS）：毫米波雷达可以测量目标的RCS，即目标对雷达信号的反射能力。通过测量目标的RCS，可以推断目标的大小、形状和材料特性。
距离测量（Range, R）：毫米波雷达能够测量目标与雷达之间的距离，从而确定目标的位置。通过计算雷达信号的往返时间，可以估计目标与雷达的距离。
速度测量（Velocity, V）：毫米波雷达可以测量目标的速度，包括径向速度和角速度。通过分析雷达信号的频移，可以计算目标的运动速度和方向。
方位角和俯仰角测量（Azimuth and Elevation, θ and φ）：毫米波雷达能够测量目标相对于雷达的方位角和俯仰角。这些角度信息对于确定目标的位置和方向至关重要。
高角分辨率：毫米波雷达具有较高的角分辨率，能够提供更精确的目标定位和角度测量。这对于多目标跟踪和目标识别非常重要。
抗干扰能力：毫米波雷达具有较强的抗干扰能力，可以在复杂的环境中工作，抵御干扰源和杂波的影响。这使得毫米波雷达在复杂场景下具有可靠的性能。
三维成像能力：毫米波雷达可以提供目标的三维成像，即在距离、方位角和俯仰角上提供详细的目标信息。这对于实现精确的环境感知和目标识别非常重要。
这些特点使得毫米波雷达在自动驾驶、安全监测、无人机控制等领域具有广泛的应用前景。

```c++
//FC radar location mapping

template <class T_RadarInTyp, class T_RadarOutTyp>
inline void mapOneRadarLoc(const T_RadarInTyp& rLoc_in, T_RadarOutTyp& rLoc_out, vfc::uint8_t idx)
{

   vfc::float32_t tempFloat32 = 0.F;
   vfc::uint8_t   tempUint8   = 0U;

   // add RFC loc mapping
   // only the NET component norming is performed by the getter function

   static_cast<void>(rLoc_in.getRFC_Loc_Dr(tempFloat32, idx));

   rLoc_out.m_LocationList.Item[idx].d = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].dVar = tempFloat32;

   rLoc_out.m_LocationList.Item[idx].v = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].vVar = tempFloat32;

   rLoc_out.m_LocationList.Item[idx].dvCov = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].dvQly = tempUint8;

   rLoc_out.m_LocationList.Item[idx].theta = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].thetaVar = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].thetaQly = tempUint8;

   rLoc_out.m_LocationList.Item[idx].phi = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].phiVar = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].phiQly = tempUint8;

   rLoc_out.m_LocationList.Item[idx].RCS = tempFloat32;
   rLoc_out.m_LocationList.Item[idx].RSSI = tempFloat32;
}
```

2. mount 
- `mount position effect`
        azimuth = self.z[2, 0] * np.cos(sensor_mount_pos.roll_offset)
        azimuth += sensor_mount_pos.yaw_offset

        dx_veh = self.z[0, 0] * np.cos(azimuth)
        dy_veh = self.z[0, 0] * np.sin(azimuth)

        dx_veh = dx_veh + sensor_mount_pos.x_offset
        dy_veh = dy_veh + sensor_mount_pos.y_offset

        line_spec = '.'
        plt.plot([dx_veh], [dy_veh], line_spec, color=color, label=label)
        plt.plot([dx_veh, dx_veh + np.cos(azimuth) * self.z[1, 0]],
                 [dy_veh, dy_veh + np.sin(azimuth) * self.z[1, 0]], color=color, alpha=0.2)

## 6/08
1. how to align two measurement between `ROS bag` and `CAN trace` 
one method, store CAN ECU timestamp to ROS topic, align these two measurement file based on timestamp signal. 

2. tmux (https://dev.to/iggredible/tmux-tutorial-for-beginners-5c52)
session --> window --> pane

## 6/09
python - `from itertools import compress`
raw_locations_filt = list(compress(raw_locations, valid_locations))
locations = list(compress(locations, is_movings))
https://stackabuse.com/pythons-itertools-compress-dropwhile-takewhile-and-groupby/


## 6/12
1. https://www.hello-algo.com/chapter_preface/about_the_book/
2. https://zh.d2l.ai/chapter_introduction/index.html

## 6/15
1. docker pull
docker pull boschicv/icv-noetic:v8.0

2. 制作容器
sudo docker run -it --privileged --name lukas -v /home/jan5szh/workspaces:/workspaces boschicv/icv-noetic:v8.0

3. How to Start Docker Container
docker start lukas

4. 进到容器内部
sudo docker exec -it lukas /bin/bash

5. sudo issue
cd /etc 
vi group,  在最后一行插入 docker:x:999:NT_ID

## 6/16
https://hbswk.hbs.edu/item/is-ai-coming-for-your-job

## 6/20
### .pth、.onnx和.trt是不同的文件格式，用于保存深度学习模型的参数和结构。它们在模型的保存和导出中扮演不同的角色。

1. .pth（PyTorch模型文件）：.pth是PyTorch框架中用于保存和加载模型参数的文件格式。当你训练好一个PyTorch模型后，可以将模型的参数保存到.pth文件中，以便在以后的推理过程中加载模型并使用这些参数进行预测。.pth文件通常只包含模型的权重参数，而不包含模型的结构信息。

2. .onnx（Open Neural Network Exchange）：.onnx是一种开放的、跨平台的深度学习模型交换格式。它可以用于在不同的深度学习框架之间转换和共享模型。通过将模型转换为.onnx格式，你可以将模型从一个框架（如PyTorch）导出到另一个框架（如TensorFlow）中，并在不同的平台上进行推理。.onnx文件包含了模型的结构和参数。

3. .trt（TensorRT模型文件）：.trt是NVIDIA的TensorRT推理引擎所使用的模型文件格式。TensorRT是针对NVIDIA GPU进行高性能深度学习推理的优化库。通过将模型转换为.trt格式，可以使用TensorRT对模型进行优化和加速，以实现更快的推理速度和更高的效率。.trt文件通常包含了模型的结构、参数和TensorRT的优化信息。

需要注意的是，这三种文件格式在使用上有一些区别和限制。.pth文件适用于PyTorch框架内部的模型加载和训练，而.onnx文件和.trt文件更适用于跨框架和高性能推理的需求。要选择合适的文件格式，需要考虑模型的导出和使用环境、目标框架和硬件平台等因素。

### DeepStream
DeepStream是NVIDIA开发的一个端到端的智能视频分析平台，旨在加速视频分析和物体识别的应用开发。它提供了一套丰富的工具和库，可用于视频流的处理、推理和分析。

DeepStream平台的主要组成部分包括以下几个方面：

1. 视频输入：DeepStream支持从各种来源获取视频流，包括摄像头、网络流媒体和本地视频文件等。

2. 视频流处理：DeepStream提供了高性能的视频流处理功能，包括解码、编码、格式转换、图像增强等。这些功能可以在硬件加速的基础上实现，以提高处理速度和效率。

3. 深度学习推理：DeepStream集成了NVIDIA的深度学习推理引擎，使用户可以在视频流上进行实时的物体检测、识别和跟踪等任务。它支持常见的深度学习框架，如TensorRT和Caffe等，并提供了高性能的GPU加速，以实现实时的推理速度。

4. 视频分析和元数据提取：DeepStream可以对视频流进行分析，提取关键的元数据信息，如物体位置、属性、运动轨迹等。这些信息可以用于进一步的应用，如行为分析、智能监控等。

5. 实时应用开发：DeepStream提供了开发工具和API，使开发人员可以快速构建基于视频分析的实时应用。它支持多路视频流的并行处理和管理，并具有灵活的配置选项和事件触发机制，以满足不同应用场景的需求。

DeepStream在各种领域有广泛的应用，包括智能监控、交通管理、智能零售、智能城市等。它的优势在于高性能的视频处理和深度学习推理能力，能够实现实时的智能视频分析，并提供了便捷的开发平台和工具，加速应用的开发和部署。

### 模型推理
当你说“模型推理”时，你指的是在使用训练好的模型进行预测或生成输出的过程。在深度学习中，模型推理通常是指在训练完成后使用已训练的模型进行预测或生成的过程。

模型推理通常分为两个主要步骤：前向传播和后处理。

1. 前向传播（Forward Propagation）：在前向传播过程中，输入数据通过模型的各个层级，从输入层传递到输出层，产生预测结果。在这个过程中，模型会利用学习到的权重和偏差，将输入数据转换为输出。前向传播过程是根据模型的结构和参数计算得出预测结果的过程。

2. 后处理（Post-processing）：在生成了模型的预测结果之后，可能需要进行后处理操作。后处理的目的是对模型的输出进行进一步的处理，以满足特定需求或约束条件。后处理的具体操作取决于应用场景和任务类型。例如，在图像分类任务中，可以使用后处理步骤来解码模型输出并得到最终的分类标签。

值得注意的是，模型推理需要在预训练的模型上进行。预训练模型是在大规模数据集上进行训练得到的，以学习通用的语言或视觉特征。在推理阶段，预训练模型被应用于具体的任务，并通过针对特定数据集的微调来提高性能。

模型推理可以应用于各种任务，如自然语言处理、图像识别、语音合成等。具体的推理过程和后处理步骤会因任务类型和具体模型而有所不同。

### 推理速度
推理速度是指深度学习模型在进行推理（即对输入数据进行预测或生成输出）时所花费的时间。快速的推理速度对于实时应用、大规模数据处理和低延迟要求的场景非常重要。

推理速度受到多个因素的影响，包括以下几个方面：

1. 模型结构和大小：模型的结构和参数数量会直接影响推理速度。通常情况下，模型越大，推理速度越慢。因此，设计轻量级模型或进行模型压缩和优化可以提高推理速度。

2. 硬件加速：使用专门的硬件加速器（如GPU、TPU等）可以显著提高推理速度。这些硬件加速器针对深度学习计算进行了优化，能够并行处理大量的矩阵运算，从而加速模型的推理过程。

3. 批处理大小：批处理大小是指同时输入到模型中进行推理的样本数量。较大的批处理大小通常可以提高推理速度，因为硬件加速器可以更好地发挥并行计算的能力。但是，过大的批处理大小可能会导致内存消耗过大，降低推理速度。

4. 模型优化：对模型进行优化和精简，如量化、剪枝、模型蒸馏等技术，可以减少模型的计算量和参数数量，从而提高推理速度。

5. 并行计算：利用并行计算技术，如模型并行和数据并行，在多个设备或多个计算单元上同时进行推理，可以加快整体的推理速度。

要提高推理速度，可以通过结构优化、硬件加速、批处理优化和模型优化等方法来实现。具体的优化策略和技术选择会受到应用场景、硬件环境和模型特点的影响。

## 6/21
### 线性神经网络 
https://zh.d2l.ai/chapter_linear-networks/linear-regression.html

## 6/25
1. make a video
In summary, Jeff shares his experience and tips on creating high-quality programming tutorials for YouTube. He emphasizes the importance of creating consistent and engaging content, focusing on improving with each video. Jeff mentions the hardware and software he uses, including a decent microphone, computer with good specs, and software like Adobe Premiere and After Effects. He also recommends using templates, stock photography, animated GIFs, and icons to enhance video production. Jeff discusses his approach to content creation, targeting intermediate-level developers and distilling content to its most efficient form. He advises learning from constructive criticism and knowing your audience's preferences. Jeff explains his video production workflow, including recording audio, adding visuals, and editing in Premiere. He highlights the significance of a captivating title and thumbnail for better visibility on YouTube. Jeff concludes by encouraging viewers to find their own path and put in the work to succeed.
 
2. A star algorithm
https://medium.com/@nicholas.w.swift/easy-a-star-pathfinding-7e6689c7f7b2
https://inside-docupedia.bosch.com/confluence/display/HADC/Overall+pipeline
A star --> https://zhuanlan.zhihu.com/p/360282185 

```markdown
A* search is a popular algorithm used in pathfinding and graph traversal. It is an informed search algorithm that efficiently finds the shortest path between two nodes in a graph.

The A* search algorithm expands nodes in a graph based on a combination of two factors: the cost to reach a node from the starting point (known as the "g" value) and an estimate of the cost to reach the goal from that node (known as the "h" value). The sum of these two values, denoted as "f = g + h," is used to prioritize the nodes for expansion.

The algorithm maintains an open list of nodes to be explored and a closed list of nodes that have already been visited. It starts with the initial node and iteratively selects the node with the lowest "f" value from the open list. The selected node is then expanded, and its neighboring nodes are evaluated and added to the open list if they haven't been visited before. The process continues until the goal node is reached or there are no more nodes to explore.

A* search incorporates an admissible heuristic function that provides a lower-bound estimate of the cost to reach the goal. This heuristic helps guide the search towards the most promising paths, making it more efficient than uninformed search algorithms like breadth-first search or depth-first search.

Overall, A* search is a widely used algorithm for finding optimal paths in graphs or grids, and it has applications in various fields such as robotics, video games, and route planning systems.
```

```c++ src/beam/behavior/gebe_planner/tactical_planning/tbp_hybrid_a_star/include/tbp_hybrid_a_star/node.h

  /// \brief Costs of the path from start to this node
  double path_costs_g_{0.0};

  /// \brief Heuristic costs of this node towards the goal
  double goal_costs_h_{0.0};

  /// \brief Complete costs of this node and its path
  double combined_costs_f_{0.0};
```

## 6/26
1. about BOSCH planning
https://inside-docupedia.bosch.com/confluence/display/CCD/UC01+in+DACore
https://inside-docupedia.bosch.com/confluence/pages/viewpage.action?pageId=2003322209
https://inside-docupedia.bosch.com/confluence/display/CCD/Standard+Algorithms
https://inside-docupedia.bosch.com/confluence/pages/viewpage.action?pageId=2130621338

2. A star for behavior plan
https://inside-docupedia.bosch.com/confluence/display/DASENA/Behavioral+Planner+-+A*+Search+Costs

## 6/27
1. Behavior Frenet projection
Behavior Frenet projection is a concept used in the field of robotics and motion planning to convert the global coordinates of a robot's desired trajectory into local coordinates based on its current position. It is particularly useful for controlling the motion of autonomous vehicles or mobile robots operating in dynamic environments.

The Frenet frame is a coordinate system that consists of two orthogonal vectors: the tangent vector and the normal vector. The tangent vector represents the direction of motion along the trajectory, while the normal vector represents the direction perpendicular to the trajectory.

When applying behavior Frenet projection, the desired trajectory is typically specified in global coordinates, such as a series of waypoints. The projection process involves determining the closest point on the trajectory to the robot's current position and then expressing the trajectory relative to that point in the Frenet frame.

The behavior Frenet projection allows the robot to plan and control its motion based on local information, such as the curvature and distance to the trajectory. By working in the Frenet frame, the robot can make decisions about its behavior, such as maintaining a desired distance from the trajectory or adjusting its speed to follow the curvature of the path.

Overall, behavior Frenet projection is a technique that enables robots to navigate along a predefined trajectory while considering their local environment and adjusting their behavior accordingly. It is a valuable tool for achieving safe and efficient motion in complex and dynamic scenarios.

## 6/28
1. tail -f
2. grep -i
3. SPAT/MAP/SSM

## 6/29
### AI
https://inside-docupedia.bosch.com/confluence/display/CCD/SoC%3A+Orin

https://inside-docupedia.bosch.com/confluence/display/DASENA/AI+Projects

https://inside-docupedia.bosch.com/confluence/display/CCD/AI_Guild_NA%3A+Members

### Grid Freespace
https://inside-docupedia.bosch.com/confluence/display/ICV/3.3+Visibility+grid+and+occupancy+grid
https://inside-docupedia.bosch.com/confluence/display/ICV/Freespace+Definition
https://inside-docupedia.bosch.com/confluence/display/TOP95/Analysis+of+Visibility+Information+for+Existence+Probalility
https://inside-docupedia.bosch.com/confluence/display/TOP95/Terminology
https://inside-docupedia.bosch.com/confluence/pages/viewpage.action?pageId=2241497967

### A star
https://inside-docupedia.bosch.com/confluence/display/DASENA/Behavioral+Planner+-+A*+Search+Costs

## 7/04
### A star search
[doc](https://inside-docupedia.bosch.com/confluence/display/DASENA/Behavioral+Planner+Code+flow)
[A-Star算法] (https://zhuanlan.zhihu.com/p/360276556)
[Dijkstra算法](https://zhuanlan.zhihu.com/p/360282185)

1. BEAM
`searchOverHorizon`
``` c++ src/beam/beam_monorepo/behavior_planning/behavioral_planner/include/behavioral_planner/search/horizon_a_star.h
  std::shared_ptr<BehavioralEnvModel> current_world; ///< \brief shared_ptr of the current behavioral environment model (for use in a priority_que)
  PredictedState ego_state;  ///< \brief ego_state defines the state of the ego vehicle
  FullBehaviorAction<BehavioralEnvModel> current_behavior; ///< \brief current_behavior is the fully defined (type and target) behavior action of this A*-search node
  double cost2come;           ///< \brief the cost to get to this node from start during A*-search
  double cost2go;             ///< \brief the (heuristic) cost to get to the horizon from this node during A*-search
  SearchNodeIntrospectionData<BehavioralEnvModel> introspection_data; ///< \brief introspection data
  bool failed;              ///< \brief failed indicates, weather an error occured in this node while traversing the A*-search graph
  double collision_probability; /// < \brief the collision probability of the current node
  bool has_clearance_costs;
  bool has_virtual_clearance_costs;
  double clearance_costs;
  Int64 relevant_stop_id;
```

2. GeBe Behaviror Planning
`solve_hybrid_a_star`
```c++ src/beam/behavior/gebe_planner/tactical_planning/tbp_hybrid_a_star/include/tbp_hybrid_a_star/node.h

  /// \brief Costs of the path from start to this node
  double path_costs_g_{0.0};

  /// \brief Heuristic costs of this node towards the goal
  double goal_costs_h_{0.0};

  /// \brief Complete costs of this node and its path
  double combined_costs_f_{0.0};
```
3. visulizate behavior Tree
https://inside-docupedia.bosch.com/confluence/display/DASENA/Features
```md
Cost=cost2come(how expensive is it to get here)+cost2go(how expensive is it from here to our goal)

cost2come=(previous)cost2come+action_cost+discount×collision_weight×collision_probability+discount×unknown_lane_intervals_intrusion_weight×unknown_lane_intervals_intrusion_score
```

/planning/BehaviorSequences
```c++
      BehavioralNodeIntrospectionData& node_data = seq_data.sequence.back();
      node_data.prediction_time = node.current_world->getElapsedTime();
      node_data.current_behavior = node.current_behavior.getBehaviorAction();
      node_data.env_model = node.current_world->getEnvironmentModel();
      node_data.planned_traj = node.current_world->getPlannedTrajectory();
      node_data.cost2come = node.cost2come;
      node_data.cost2go = node.cost2go;
      node_data.action_cost = node.introspection_data.action_cost;
      node_data.collision_prob = node.introspection_data.collision_prob;
      node_data.collision_cost = node.introspection_data.collision_cost;
      node_data.unknown_lane_intervals_intrusion_cost = node.introspection_data.unknown_lane_intervals_intrusion_cost;
      node_data.action_cost = node.introspection_data.action_cost;
      node_data.failed = false;
      node_data.is_lane_change_abort = node.introspection_data.is_lane_change_abort;
      node_data.collision_information.insert(node_data.collision_information.end(),
                                             node.introspection_data.debug_collision_aux_info_for_worlds.begin(),
                                             node.introspection_data.debug_collision_aux_info_for_worlds.end());
```

### C++ hack
https://hackingcpp.com/

## 7/10
### TOP95 UC2 description
https://inside-docupedia.bosch.com/confluence/display/TOP95/DDD-201+-+Operational+Design+Domain+%28ODD%29+and+Corner+Cases+of+UC2